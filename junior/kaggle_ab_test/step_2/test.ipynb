{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ttest import cross_val_score, prepare_dataset, compare_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset using make regression\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "data, target = make_regression(n_samples=1000, n_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=200)\n",
    "params_list = [\n",
    "    {\"max_depth\": 10},  # baseline\n",
    "    {\"max_depth\": 2},\n",
    "    {\"max_depth\": 3},\n",
    "    {\"max_depth\": 4},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/btseitlin/Documents/simulator-ml/junior/kaggle_ab_test/step_2/baseline.py:117: RuntimeWarning: invalid value encountered in log1p\n",
      "  fold_model.fit(X_train, np.log1p(y_train))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/btseitlin/Documents/simulator-ml/junior/kaggle_ab_test/step_2/test.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/btseitlin/Documents/simulator-ml/junior/kaggle_ab_test/step_2/test.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m r2_score\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/btseitlin/Documents/simulator-ml/junior/kaggle_ab_test/step_2/test.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m result \u001b[39m=\u001b[39m cross_val_score(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/btseitlin/Documents/simulator-ml/junior/kaggle_ab_test/step_2/test.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     model,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/btseitlin/Documents/simulator-ml/junior/kaggle_ab_test/step_2/test.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     X\u001b[39m=\u001b[39mdata,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/btseitlin/Documents/simulator-ml/junior/kaggle_ab_test/step_2/test.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     y\u001b[39m=\u001b[39mtarget,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/btseitlin/Documents/simulator-ml/junior/kaggle_ab_test/step_2/test.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/btseitlin/Documents/simulator-ml/junior/kaggle_ab_test/step_2/test.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     scoring\u001b[39m=\u001b[39mr2_score,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/btseitlin/Documents/simulator-ml/junior/kaggle_ab_test/step_2/test.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     params_list\u001b[39m=\u001b[39mparams_list,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/btseitlin/Documents/simulator-ml/junior/kaggle_ab_test/step_2/test.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/simulator-ml/junior/kaggle_ab_test/step_2/baseline.py:117\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(model, X, y, cv, params_list, scoring, random_state, show_progress)\u001b[0m\n\u001b[1;32m    115\u001b[0m fold_model \u001b[39m=\u001b[39m copy(model)\n\u001b[1;32m    116\u001b[0m fold_model\u001b[39m.\u001b[39mset_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m--> 117\u001b[0m fold_model\u001b[39m.\u001b[39;49mfit(X_train, np\u001b[39m.\u001b[39;49mlog1p(y_train))\n\u001b[1;32m    118\u001b[0m y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpm1(fold_model\u001b[39m.\u001b[39mpredict(X_test))\n\u001b[1;32m    120\u001b[0m score \u001b[39m=\u001b[39m scoring(y_test, y_pred)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:331\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mif\u001b[39;00m issparse(y):\n\u001b[1;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 331\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    332\u001b[0m     X, y, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mDTYPE\n\u001b[1;32m    333\u001b[0m )\n\u001b[1;32m    334\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    335\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/utils/validation.py:1090\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1071\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1072\u001b[0m     )\n\u001b[1;32m   1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1075\u001b[0m     X,\n\u001b[1;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1088\u001b[0m )\n\u001b[0;32m-> 1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39;49mmulti_output, y_numeric\u001b[39m=\u001b[39;49my_numeric, estimator\u001b[39m=\u001b[39;49mestimator)\n\u001b[1;32m   1092\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1094\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/utils/validation.py:1100\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m multi_output:\n\u001b[0;32m-> 1100\u001b[0m     y \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1101\u001b[0m         y,\n\u001b[1;32m   1102\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1103\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1104\u001b[0m         ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1105\u001b[0m         dtype\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1106\u001b[0m         input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1107\u001b[0m         estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1108\u001b[0m     )\n\u001b[1;32m   1109\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1110\u001b[0m     estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/utils/validation.py:899\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    894\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    896\u001b[0m         )\n\u001b[1;32m    898\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 899\u001b[0m         _assert_all_finite(\n\u001b[1;32m    900\u001b[0m             array,\n\u001b[1;32m    901\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    902\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    903\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    904\u001b[0m         )\n\u001b[1;32m    906\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    907\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/utils/validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    125\u001b[0m             \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[1;32m    126\u001b[0m             \u001b[39mand\u001b[39;00m estimator_name\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    131\u001b[0m             \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m             msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    133\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m             )\n\u001b[0;32m--> 146\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n\u001b[1;32m    148\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "result = cross_val_score(\n",
    "    model,\n",
    "    X=data,\n",
    "    y=target,\n",
    "    cv=3,\n",
    "    scoring=r2_score,\n",
    "    params_list=params_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/btseitlin/Documents/simulator-ml/junior/kaggle_ab_test/step_2/test.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/btseitlin/Documents/simulator-ml/junior/kaggle_ab_test/step_2/test.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m result\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold\n",
      "   model_index  avg_score   p_value  effect_sign\n",
      "0            3   0.570022  0.070749            0\n",
      "1            4   0.569075  0.043978            1\n",
      "2            2   0.567321  0.117041            0\n",
      "3            5   0.559491  0.066653            0\n",
      "4            6   0.553175  0.038987           -1\n",
      "5            7   0.550585  0.002375           -1\n",
      "6            8   0.542542  0.007814           -1\n",
      "7            1   0.502750  0.000799           -1\n"
     ]
    }
   ],
   "source": [
    "data_path = \"train.csv.zip\"\n",
    "random_state = 42\n",
    "cv = 5\n",
    "params_list = [\n",
    "    {\"max_depth\": 10},  # baseline\n",
    "    {\"max_depth\": 2},\n",
    "    {\"max_depth\": 3},\n",
    "    {\"max_depth\": 4},\n",
    "    {\"max_depth\": 5},\n",
    "    {\"max_depth\": 9},\n",
    "    {\"max_depth\": 11},\n",
    "    {\"max_depth\": 12},\n",
    "    {\"max_depth\": 15},\n",
    "]\n",
    "\n",
    "X, y = prepare_dataset(data_path)\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=200, n_jobs=-1, random_state=random_state\n",
    ")\n",
    "\n",
    "result = compare_models(\n",
    "    cv=cv,\n",
    "    model=model,\n",
    "    params_list=params_list,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    random_state=random_state,\n",
    "    show_progress=True,\n",
    ")\n",
    "print(\"KFold\")\n",
    "print(pd.DataFrame(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold\n",
      "   model_index  avg_score  effect_sign\n",
      "0            1   0.503042           -1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nAssertionError: Function 'cross_val_score' returns incorrect value for RandomForestRegressor. For example, for max_depth=2, random_state=42, n_estimators=50, cv=5, scoring=r2_score you should get [0.50666363 0.36732098 0.52903007 0.56666586 0.54552863], but you get [0.56432716 0.40892336 0.55204628 0.53879416 0.56933918]\\n\\nAssertionError: Function 'compare_models' returns incorrect value. For example, for params_list=[{'max_depth': 10}, {'max_depth': 2}, {'max_depth': 3}, {'max_depth': 12}, {'max_depth': 15}] , cv=5, you should get 'effect_sign' for models '[1, -1, -1, -1], but you get for models '[-1, 1, -1, -1]\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"train.csv.zip\"\n",
    "random_state = 42\n",
    "cv = 5\n",
    "params_list = [\n",
    "    {\"max_depth\": 10},  # baseline\n",
    "    {\"max_depth\": 2},\n",
    "]\n",
    "\n",
    "X, y = prepare_dataset(data_path)\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=50, n_jobs=-1, random_state=random_state\n",
    ")\n",
    "\n",
    "result = compare_models(\n",
    "    cv=cv,\n",
    "    model=model,\n",
    "    params_list=params_list,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    random_state=random_state,\n",
    "    show_progress=True,\n",
    ")\n",
    "print(\"KFold\")\n",
    "print(pd.DataFrame(result))\n",
    "\n",
    "\"\"\"\n",
    "AssertionError: Function 'cross_val_score' returns incorrect value for RandomForestRegressor. For example, for max_depth=2, random_state=42, n_estimators=50, cv=5, scoring=r2_score you should get [0.50666363 0.36732098 0.52903007 0.56666586 0.54552863], but you get [0.56432716 0.40892336 0.55204628 0.53879416 0.56933918]\n",
    "\n",
    "AssertionError: Function 'compare_models' returns incorrect value. For example, for params_list=[{'max_depth': 10}, {'max_depth': 2}, {'max_depth': 3}, {'max_depth': 12}, {'max_depth': 15}] , cv=5, you should get 'effect_sign' for models '[1, -1, -1, -1], but you get for models '[-1, 1, -1, -1]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50666363, 0.36732098, 0.52903007, 0.56666586, 0.54552863])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"train.csv.zip\"\n",
    "random_state = 42\n",
    "cv = 5\n",
    "params_list = [\n",
    "    {\"max_depth\": 10},  # baseline\n",
    "    {\"max_depth\": 2},\n",
    "]\n",
    "\n",
    "X, y = prepare_dataset(data_path)\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=50, n_jobs=-1, random_state=random_state\n",
    ")\n",
    "\n",
    "result = cross_val_score(\n",
    "    model,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    cv=cv,\n",
    "    scoring=r2_score,\n",
    "    params_list=params_list,\n",
    ")\n",
    "result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
